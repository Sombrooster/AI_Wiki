<!DOCTYPE html>
<html lang=en>
    <head>
        <meta charset="UTF-8">
        <title>AI WIKI</title>
        <link href="wiki.css" rel="stylesheet" type="text/css"/>
    </head>

    <body>
        <h1>Artificial Intelligence</h1>

        <!-- INDEX TABLE -->
        <table>
            <tr>
                <td><div class="img"><img src="https://www.extremetech.com/wp-content/uploads/2015/09/sat-ai-head-640x353.jpg"
                         alt="Artificial Intelligence">
                    Digital Brain <a href="#20">[20]</a></div></td>
            </tr>
            <tr>
                <td class="title">Index</td>
            </tr>
            <tr>
                <td class="main"><a href="#Introduction">Introduction</a></td>
            </tr>
            <tr>
                <td class="main"><a href="#Types">Types</a></td>
            </tr>
                <tr>
                    <td class="sub"><a href="#Strong_AI">Strong AI</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Weak_AI">Weak AI</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Intelligent_Agents">Intelligent Agents</a></td>
                </tr>
            <tr>
                <td class="main"><a href="#Methods">Methods</a></td>
            </tr>
                <tr>
                    <td class="sub"><a href="#Traditional">Traditional</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Evolutionary">Evolutionary</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#ANN">Artificial Neural Networks</a></td>
                </tr>
            <tr>
                <td class="main"><a href="#Practical_Application">Practical Applications</a></td>
            </tr>
                <tr>
                    <td class="sub"><a href="#Optimization">Optimization</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Transportation">Transportation</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Human_Interaction">Human Interaction</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Marketing">Marketing</a></td>
                </tr>
            <tr>
                <td class="main"><a href="#History">History</a></td>
            </tr>
                <tr>
                    <td class="sub"><a href="#Pre-Computer">Pre-Computer</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Turing_Test">Turing Test</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#To_Today">To Today</a></td>
                </tr>
            <tr>
                <td class="main"><a href="#Future">Potential Future</a></td>
            </tr>
                <tr>
                    <td class="sub"><a href="#Widespread_Adoption">Widespread Adoption</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Integration">Integration</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Potential_Positives">Positives</a></td>
                </tr>
                <tr>
                    <td class="sub"><a href="#Potential_Negatives">Negatives</a></td>
                </tr>
            <tr>
                <td class="main"><a href="#Conclusion">Conclusion</a></td>
            </tr>
            <tr>
                <td class="main"><a href="#References">References</a></td>
            </tr>
        </table>

        <h2>The types, methods, application, history, and potential future of Artificial Intelligence</h2>
        <p style="font-size: 12pt; margin-top: -10px; margin-bottom: -15px;">by Cash FitzGibbons, Chase Cowley, and Steven Klassen</p>



        <h3 id="Introduction">Introduction</h3>
            <p>The computational attempt of imitating human intelligence in order to solve a problem given specific
                variables using logic. Artificial Intelligence ranges from simplistic rational agents, following given
                steps to reach the desired end, to advanced multilayered general-purpose neural networks, which attempt
                to imitate, match, or succeed the capabilities of human intelligence. There are different types,
                methods, and applications of artificial intelligence. The History of AI goes as far back as the 13th
            Century but only gained traction with Alan Turing and the Conference for Artificial Intelligence in 1956.
            The Adoption of Artificial Intelligence can be seen in many different fields of studies automating transportation
            healthcare, and certain aspects of finance.</p>

        <h3 id="Types">Types</h3>
            <h4 id="Strong_AI">Strong Artificial Intelligence</h4>
                <p class="h4">Matches or succeeds human intelligence, is capable of performing any given
                    task <a href="#13">[13]</a>. This kind of AI does not exist as of 2018.</p>

            <h4 id="Weak_AI">Weak Artificial Intelligence</h4>
                <p class="h4">Designed to solely perform specific subset of intelligent actions<a href="#13">[13]</a>.</p>


            <h4 id="Intelligent_Agents">Intelligent Agents</h4>
                <p class="h4">An agent is any entity that perceives its environment through sensors and reacts upon
                environment through effectors. A rational agent will do the right thing given what it believes from
                what it perceives. In order to achieve maximum success, the agent should be able to decide what is
                the right thing, and how and when to evaluate success <a href="#13">[13]</a>.</p>

                <h5>Simple Reflex Agent</h5>
                    <p class="h5">Detects and interprets its environment, uses a set of rules to decide next action,
                    and then acts out on the calculated response <a href="#13">[13]</a>.</p>
                <h5>Model Based Reflex</h5>
                    <p class="h5">Detects and interprets its environment, keeps record of how world continues to change
                    and the cause and effect relationship between its actions and this change, uses set of rules and
                    the experience it has gathered to act out on a calculated response <a href="#13">[13]</a>.</p>
                <h5>Goal-Based Agents</h5>
                    <p class="h5">Detects and interprets its environment, keeps record of how world continues to change
                    and the cause and effect relationship between its actions and this change, theorizes how its actions
                    will change the environment before acting out on them, uses set of goals to achieve to calculate
                    its next action <a href="#13">[13]</a>.</p>
                <h5>Utility-Based Agents</h5>
                    <p class="h5">Detects and interprets its environment, keeps record of how world continues to change
                    and the cause and effect relationship between its actions and this change, theorizes how its actions
                    will change the environment, uses weights to measure how this change will fulfill its utility, acts
                    on action if it beneficial towards the given goal <a href="#13">[13]</a>.</p>
                <h5>Learning Agents</h5>
                    <p class="h5">Detects and interprets its environment, evaluates effectiveness of all previous
                    actions compared to the most recent action as according to a set performance standard, utilizes a
                    learning element to modify its approach and theorizes potential future issues, then acts
                    accordingly to what was learned <a href="#13">[13]</a>.</p>


        <h3 id="Methods">Methods of Artificial Intelligence</h3>
            <h4 id="Traditional">Traditional Algorithms</h4>
                <p class="h4">A fail-safe procedure, guaranteed to achieve a specific goal <a href="#2">[2]</a> or the
                              formal computation of a step-by-step sequence which achieves a desired output.
                              The first notion of an algorithm begins with al-Khowarazmi, the Arabian
                              mathematician who introduced numerals and algebra to Western Society. Algorithms were
                              not given a formal mathematical syntax until George Boole's Boolean Algebra, which was
                              later expanded upon by Gottlob Frege and Alfred Tarski <a href="#4">[4]</a>.</p>

                <h5>Logical Positivism</h5>
                    <p class="h5">Connects observational sentences to sensory input. Confirmation theory attempts to
                        further actualize how knowledge can be acquired from experience.
                        Rooted in the empiricist movement in the 17th century, logical positivism was shaped
                        by Bertrand Russell around the turn of the 20th century, which was expanded upon by Confirmation
                        Theory of Rudolf Carnap and Carl Hempel <a href="#4">[4]</a>.</p>

                <h5>Heuristics </h5>
                    <p class="h5">An algorithm which can not guarantee a correct answer which works as a procedure to
                        infer the most likely correct answer. Heuristics can be used to estimate noncomputable programs
                        and are usually correct, but not always correct <a href="#2">[2]</a>. Heuristics are commonly
                        analogized by the means-ends analysis of a problem, which involves the computation of the
                        difficulty of functions served, which functions are required, and the means by which to
                        approach the problem <a href="#4">[4]</a>.</p>

            <h4 id="Evolutionary">Evolutionary Algorithms</h4>
                <p class="h4">A large set of generated programs are given a set of inputs
                    and the expectation of a certain output. The first “generation” usually
                    does poorly, but, by random chance, some will outperform their
                    counterparts. The programs who performed best then are used to
                    psuedo-randomly create the next “generation” using the variables of their interworkings
                    as a seed. This cycle is repeated until a program that can perform the task at hand with
                    great accuracy is created <a href="#1">[1]</a>.</p>

                <h5>Genetic Algorithms</h5>
                    <p class="h5">Genetic algorithms are a subsection of evolutionary algorithms. They detect the
                        fitness of successful programs within the generation and analyze specific
                        successful patterns found within the interworkings of the programs and organize them into
                        'chromosomes' or 'gene'. Allows for a more efficient creation process of the next generation
                        by identifying which aspects of the logic used to achieve the correct answer are most
                        effective <a href="#4">[4]</a><a href="#14">[14]</a>.</p>

            <div class="img"><img src="http://www.texample.net/media/tikz/examples/PNG/neural-network.png"
                      alt="Artificial Neural Network Diagram">Artificial Neural Network Diagram <a href="#17">[17]</a></div>
            <h4 id="ANN">Artificial Neural Networks </h4>
                <p class="h4">An imitation of biological neural networks in the brain, Artificial Neural Networks use
                    examples given to automatically infer rules of a given desired input and output. Adding
                    examples increases the accuracy of the Neural Network <a href="#3">[3]</a>. Each artificial
                    neuron has one output and a many inputs. Each input will have a weight associated
                    with it which determines how much the input affects a neuron's single output. This output is
                    determined by adding the weights of all inputs that receive a 1, and if a certain threshold is
                    reached, the output is 1 <a href="#2">[2]</a>.</p>

                <h5>Deep Learning </h5>
                    <p class="h5"> Deep Convolutional Neural Networks are a commonly used and effective approach in the
                        utilization of neural network. They are distinguished by their use of <b>local receptive fields,
                            shared weights, </b> and <b> pooling </b> <a href="#3">[3]</a>.</p>

                    <h6>Local Receptive Fields</h6>
                        <p class="h6">Determines which parts of the data prove to be most consistently useful, breaking
                            down the data into its most important variables <a href="#3">[3]</a>.</p>

                    <h6>Shared Weights</h6>
                        <p class="h6">Uses hidden layers to analyze specific sections of the data for specific patterns
                            and shares the weights of the useful detected patterns with the other layers. This applies
                            a feature detector throughout the data <a href="#3">[3]</a>.</p>

                    <h6>Pooling</h6>
                        <p class="h6">Generalizes the data by by asking whether a given feature within the data is
                            found. The exact positional information is discarded, and is replaced with its rough
                            location relative to other features. This gives the network an intuition overlooking any
                            specifics dynamic variables or anomalies within the data <a href="#3">[3]</a>.</p>


        <h3 id="Practical_Application">Practical Applications</h3>
            <div class="img"><img src="https://upload.wikimedia.org/wikipedia/commons/e/ec/ParticleSwarmArrowsAnimation.gif"
                                  alt="AI Optimization Visual">AI Optimization <a href="#18">[18]</a></div>

            <h4 id="Optimization">Optimization</h4>
                <p class="h4">Commonly utilizes the <a href="#Evolutionary">Genetic Algorithm</a> to create a program
                which can optimize functionality and sort data at a rate much faster than any human being could
                program themselves. These can exist as the entire agent function with a sole purpose to optimize
                or as a component function, in which case it acts as the critic of its actions<a href="#4">[4]</a>.</p>

            <h4>Automation</h4>
                <p class="h4">Automation of many different fields of employment</p>
                <h5 id="Transportation">Transportation</h5>


            <h4 id="Human_Interaction">Human Interaction</h4>

                <h5>Personal Assistant</h5>

                <h5>Voice Recognition</h5>

                <h5>Facial Recognition</h5>


            <h4 id="Marketing">Marketing</h4>
                <p class="h4">The internet has recently utilized artificial intelligence to maximize the amount of
                time a user spends on a given website or the amount of money a user is willing to spend and what
                specific products a user would want to buy. This is determined through a combination of a user's
                internet history and its measurement by the success rate of the desired action of the user
                <a href="#1">[1]</a>. This kind of artificial intelligence can be seen all throughout the internet
                and can force a user into their own "bubble" of the internet, where they can only be exposed to
                certain information at the discretion of an 'all knowing algorithm'.</p>


        <h3 id="History">History</h3>

            <h4 id="Pre-Computer">Pre-Computer (13th Century-20th Century_</h4>
                <p class="h4">The history of Artificial Intelligence goes back a very long way. Especially when talking
                    about Artificial Intelligence before computers were ever even invented. In the 13thCentury, Ramon
                    Lull a Spanish theologian, invented machines for discovering non-mathematical truths through
                    combinatorics. Moving all the way up to about 1642, Pascal created the first mechanical digital
                    calculating machine. And jumping to 1801, Joseph-Marie Jacquard invented the Jacquard loom, which
                    was the first programmable machine and it would take instructions via punched cards <a href="#5">[5]</a>. Looking
                    at these big steps taken in A.I. history, there was a huge gap in time between each major
                    achievement. As time progressed and got closer to what is now the present, the gap in time between
                    major achievements was shortened significantly. But since they were spread out with such wide gaps
                    in time, there were not very many achievements before the computer itself was actually invented.</p>

            <div class="img"><img src="https://upload.wikimedia.org/wikipedia/commons/5/55/Turing_test_diagram.png"
                                  alt="Turing Test">Turing Test Diagram <a href="#15">[15]</a></div>
            <h4 id="Turing_Test">Turing Test (1950)</h4>
                <p class="h4">Moving along to a major piece of the Artificial Intelligence timeline is the
                    ‘Turing Test’. The Turing Test was invented in 1950 by Alan Turing. Alan Turing was a English
                    philosopher, mathematic, and computer scientist, he was born in 1912 and played vital roles in
                    helping defeat the Nazi Germans during World War 2. He moved on to the Turing Test after fighting
                    in WW2 and its purpose was to determine if a computer was smart enough to outsmart a human judge.
                    How it went down was there were 3 separate rooms: one room contained a computer, another room
                    contained a human being, and the third room contained a living human judge to decide the final
                    results. None of the three participants knew who was in what room. The judge would then ask a
                    question to both of the rooms via typing it/writing it on a piece of paper. After that, the human
                    in one of the rooms would then attempt to answer the question at the best of their knowledge and
                    the computer would answer the question as well. Once the computer and human have answered the
                    question the judge will look over the answers. If the judge cannot determine which room the computer
                    is in based off of the computer’s answer, then the computer has passed the Turing Test. This a very
                    tough accomplishment for any of the computers of the 1950s and rarely was it passed. The question
                    that Turing believed the Test itself had answered is that machines have the ability to think
                    similarly to the way humans do. Which is the one of the main reasons why he pursued inventing a
                    test as such. Although the test did not age well, as now a day’s people do not rely on the nature of
                    the test and don’t think it is a reliable test with how smart computers are. </p>

            <div class="img"><img src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2015/01/Howard-Graph.png"
                                  alt="Computer Progress">Progress of AI <a href="#16">[16]</a></div>
            <h4 id="To_Today">To Today (1956 - Today)</h4>
                <p class="h4">
                    After the Turing Test, achievements in Artificial Intelligence started to skyrocket in numbers.
                    Including the first ever name and conference for Artificial Intelligence. In 1956, John McCarthy
                    came up with the term ‘Artificial Intelligence’ as the topic of the Dartmouth Conference. Which was
                    the very first ever conference devoted solely to the studies of Artificial Intelligence. And right
                    after that in 1962, the very first industrial robot company was founded known as, Unimation <a href="#7">[7]</a>.
                    During this time (1956-1974) is what was known as “The Golden Years.” There were major steps taken
                    during this era, steps such as computers gaining the ability to do math problems with ease and
                    learning to speak different languages.  In 1972, Waseda University began creating a humanoid robot
                    in 1967 and by 1972 they invented the WABOT-1, known as the very first artificially intelligent
                    humanoid robot <a href="#15">[15]</a>. But then Artificial Intelligence hit a stone cold stop after 1974. The A.I.
                    researchers had made so many promises and had such high expectations of their goals and achievements
                    that they failed to deliver many of the things they promised to their boosters and eventually the
                    funding for Artificial Intelligence came to a halt. The year 1980 was then known as the “Boom.” A
                    form of A.I. program called “expert systems” was adopted by many corporations around the world and
                    intelligence had become the main focus of Artificial Intelligence research. But then in 1987, the
                    field started to get heavily criticized yet again. Known as the “Second AI Winter” a huge chunk of
                    the funding towards Artificial Intelligence was pulled and AI had yet another setback <a href="#15">[15]</a>.
                    However, Artificial Intelligence Research bounced back in a big way. With major achievements in the
                    field; in 1997, IBM’s Deep Blue System defeated the world champion of chess. In 1997, NASA’s
                    pathfinder mission made a successful landing and the first autonomous robotics system, Sojourner,
                    was deployed on the surface of Mars. In 2011, Natural Language Processor ‘Siri’ was released to the
                    public and was the first of its kind. Again in 2011, IBM’s Watson won the Jeopardy! Game show and
                    it was honestly not even close, the Artificially Intelligent computer slaughtered its opponents.
                    And in 2014, “Chatbot” tricked judges during the Turing Test into thinking it was a real human being.
                    With all of these major accomplishments already behind us, there is nowhere to go except forward.
                    Many researchers believe that we have only scratched the surface when it comes to Artificial
                    Intelligence and we have a very long way to go until we see the restrictions A.I. has in itself.
                    Researchers believe that this image represents where we stand in time right now compared to what the
                    capabilities are for Artificial Intelligence in the distant future. Researchers have learned from
                    the past that they should not be giving timelines on when the next big step may be achieved because
                    of two reasons: in the past when researchers had given an estimation of when they should have
                    something completed by, their funds were pulled from underneath them and landed them in the first
                    A.I. Winter. And two because we have no idea what the next major achievement in Artificial
                    Intelligence might be. It could be the ability to learn multiple languages at once or solve math
                    problems faster than it can create them. We just have to wait and see.
                </p>



        <h3 id="Future">Potential Future of AI </h3>
            <div class="img"><img src="https://www.ibm.com/watson/assets/duo/img/homepage/Watson_Avatar_Ambient-square-071817-homepage_1.jpg"
                                  alt="Computer Progress">IBM Watson<a href="#21">[21]</a></div>
            <h4 id="Widespread_Adoption">Widespread Adoption</h4>
                <p class="h4">The integration in regards to our technology and A.I., is one that will not be as difficult as most
                    people would think.The widespread adoption of Artificial Intelligence is one that we will eventually see
                    in our lifetime, and are already somewhat seeing in today's day and age. One example would
                    be the fact that everyone's phone most likely has some sort of helping A.I., and we can
                    expect in the future that It will be more complex based on the expectations of A.I. Businesses will
                    also take advantage of AI in the sense to use it for an advantage against other companies that do
                    not have access to a sustainable source of information that AI will eventually provide, most likely
                    for a price.</p>
                <ul>
                    <li><b>Healthcare Adoption</b> - Probably one of the most beneficial adaptations that Artificial
                        intelligence is capable of, healthcare is something that will benefit drastically from
                        integration of some sort of AI. The widespread adoption of Artificial Intelligence into
                        healthcare is less than 5 years away, according to professionals that were surveyed by Intel
                        and Convergys <a href="#6">[6]</a>. From this survey, 83 percent are predicting better diagnosis capabilities,
                        and three quarters from the survey say that artificial intelligence capabilities would be able
                        to take care of tasks to allow clinicians to spend more time with their patients.</li>
                    <li><b>Finance Adoption</b> - Artificial intelligence integration into finance is very similar to
                        that of healthcare. Mainly artificial intelligence would be used primarily for efficiency in non
                        efficient areas such as an automated billing systems, which in turn increases the frequency of
                        information received by the client <a href="#8">[8]</a>. Some disadvantages of this though is that it might cost
                        a lot of money to the point of firms rethinking already successful business models. People that
                        already have immense knowledge in the financial field though, will most likely be placed in very
                        important positions that AI does not take care of.</li>
                    <li><b>National Security</b> -Artificial intelligence and its significance on our national security
                        is one that is already developing in our time and will continue to develop over the years.
                        Artificial intelligence use in national security so far in our country has been primarily used
                        in the field of war. This brings up the question also of ethics in national security, and what
                        can be delegated to the machine, and what can be delegated to the people on the side that made
                        the machine <a href="#9">[9]</a>. The Department of Defense has stated that the ultimate decision of killing
                        another human being will always be left to humans, but artificial intelligence could select a
                        goal to accomplish long term based on the full understanding of the world, and the complexities
                        of it as well <a href="#10">[10]</a>.</li>
                </ul>

            <h4 id="Potential_Positives">Positives</h4>
            <div class="img"><img src="https://www.extremetech.com/wp-content/uploads/2017/07/Cadillac-super-cruise-illo-clip-640x315.jpg"
                                  alt="Self Driving Car">Self Driving Car<a href="#22">[22]</a></div>
                <ul>
                    <li><b>Self driving vehicles</b> - Artificial intelligence in vehicles is a very high stake type of
                        project in the field of AI. If we hope to eventually see a mass of self driving cars, cars will
                        need to be able to process the large amount of data that it will take in on a daily commute.
                        They will have to be able to determine things such as whether or not the thing in front of the
                        vehicle is a person, a fire hydrant, or a trash can. This will require plenty of computing
                        power, and an equal amount of code to perform safe actions <a href="#11">[11]</a>.</li>
                    <li><b>Geological studies and predictions</b> - Artificial intelligence is already participating in
                        the predictions of natural disasters, and progressively making an effort to understand natural
                        disasters in general. Artificial intelligence is very good in terms of speed and volume, but in
                        the case of predictions for natural disasters, the quality is not as good. It is easy to predict
                        where the line will go between two close adjacent points, but it is much much more difficult to
                        determine the correlation between two points that are very far apart, and whether or not they
                        will change <a href="#12">[12]</a>.</li>
                </ul>
            <h4 id="Potential_Negatives">Negatives</h4>
                <ul>
                    <li><b>Surpassing Man</b> - An artificial intelligence that can think and act in superior ways than
                        a human can. (This is probably not in our lifetime, as the process of making a artificial
                        intelligence based solely on the neurological pathways in our brains is very complex. The only
                        way that an artificial intelligence can surpass human kind is if the people that made it in the
                        first place allow it to, at least for now. Due to the development of artificially intelligent
                        supercomputers, the people on earth will need to create a science for understanding the
                        artificial intelligence, due to its intellectual superiority. Once an artificial intelligence
                        is complex enough to think for itself, it will seek ways to further its resources, as well as
                        seeking ways to avoid things called failure modes, or in other terms, being turned off
                        <a href="#19">19</a>.</li>
                    <li>The room for human creativity in the technological might be squandered if the
                        artificial intelligence that’s integrated is designed to think for itself
                        and not for the person using it.</li>
                </ul>

        <h3 id="Conclusion">Conclusion</h3>
            <p></p>

        <h3 id="References">References</h3>
            <ol>
                <li id="1">[1] CGPGrey, “How Machines Learn,” YouTube, 18-Dec-2017. [Online].
                    Available: https://www.youtube.com/watch?v=R9OHn5ZF4Uo. [Accessed: 09-Oct-2018].</li>
                <li id="2">[2] W. D. Hillis, Pattern on the stone: the simple ideas that make computers work.
                    New York, NY: Basic Books, 2015.</li>
                <li id="3">[3] Michael A. Nielsen, "Neural Networks and Deep Learning", Determination Press, 2015</li>
                <li id="4">[4] S. J. Russell and P. Norvig, Artificial intelligence: a modern approach.
                    Englewood Cliffs, NJ: Prentice-Hall, 1995.</li>

                <li id="5">[5] “A Brief History of AI,” AITopics. [Online]. Available: https://aitopics.org/misc/brief-history.
                    [Accessed: 09-Oct-2018]. </li>
                <li id="6">[6]  “U.S. Healthcare Leaders Expect Widespread Adoption of Artificial Intelligence by 2023”
                    newsroom.intel.com, July 2nd, 2018 [Online] Available:
                    https://newsroom.intel.com/news-releases/u-s-healthcare-leaders-expect-widespread-adoption-artificial-intelligence-2023/
                    [Accessed 26-Oct-2018]</li>
                <li id="7">[7] T. Lewis, “A Brief History of Artificial Intelligence,” LiveScience, 04-Dec-2014. [Online]. Available:
                    https://www.livescience.com/49007-history-of-artificial-intelligence.html. [Accessed: 09-Oct-2018].</li>
                <li id="8">[8] “AI’s impact on accounting and finance” www.forbes.com Sept 10, 2018 [Online] Available:
                    https://www.forbes.com/sites/theyec/2018/09/10/ais-impact-on-accounting-and-finance/#593de484e855
                    [Accessed 25 Oct 2018]</li>
                <li id="9">[9] “Artificial Intelligence and National Security” fas.org, April 26, 2018, [Online]
                    Available https://fas.org/sgp/crs/natsec/R45178.pdf [Accessed 26 Oct 2018] </li>
                <li id="10">[10] “The implications of artificial intelligence for national security strategy”
                    brookings.edu, November 1, 2018, [Online] Available:
                    https://www.brookings.edu/research/the-implications-of-artificial-intelligence-for-national-security-strategy/
                    [Accessed 26-Oct-2018]</li>
                <li id="11">[11] “Why AI is Tipping the Scales in the Development of self-driving Cars.”
                    knowledge.wharton.upenn.edu Nov 16, 2017 [Online] Available:
                    http://knowledge.wharton.upenn.edu/article/ai-tipping-scales-development-self-driving-cars/
                    [Accessed 26 Oct 2018]</li>
                <li id="12">[12] “AI Could help us manage natural disasters - but only to an extent.”
                    theconversation.com, September 19, 2018, [Online] Available:
                    https://theconversation.com/ai-could-help-us-manage-natural-disasters-but-only-to-an-extent-90777
                    [Accessed 28 Oct 2018]</li>
                <li id="13">[13] J. Weese, CIS 115. Class Lecture, Topic:"16-Artificial Intelligence", College of Engineering,
                    Kansas State University, Manhattan, Kansas, Oct. 25, 2018.</li>
                <li id="14">[14] "Introduction to genetic algorithms: IV. Genetic Algorithm". Retrieved 12 August 2015.</li>
                <li id="15">[15]“History of artificial intelligence,” Wikipedia, 25-Nov-2018. [Online]. Available:
                    https://en.wikipedia.org/wiki/History_of_artificial_intelligence. [Accessed: 27-Nov-2018].</li>
                <li id="16">[16]“The Artificial Intelligence Revolution: Part 2,” Wait But Why, 20-Dec-2017. [Online].
                    Available: https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html.
                    [Accessed: 27-Nov-2018].</li>
                <li id="17">[17] “Example: Neural network,” TeXample.net. [Online]. Available:
                    http://www.texample.net/tikz/examples/neural-network/. [Accessed: 27-Nov-2018].</li>
                <li id="18">[18] Ephramac, ParticleSwarmArrowsAnimation. Wikipedia, 2017.</li>
                <li id="19">[19] “What Happens When Artificial Intelligence Turns On Us?” smithsonianmag.com,
                    January 21, 2014, [Online] Available:
                    https://www.smithsonianmag.com/innovation/what-happens-when-artificial-intelligence-turns-us-180949415/
                    [Accessed 28 Oct 2018]</li>
                <li id="20">[20] J. Hruska, Colorful Circuit Brain. Ziff Davis, LLC. PCMag Digital Group, 2018.</li>
                <li id="21">[21] Watson Logo.
                    IBM Available: https://www.ibm.com/watson/assets/duo/img/homepage/Watson_Avatar_Ambient-square-071817-homepage_1.jpg/
                    [Accessed 28 Nov 2018].</li>
                <li id="22">[22] B. Howard, “How Self-Driving Cars Work, and When They'll Get Real,” ExtremeTech,
                    10-Jul-2018. [Online]. Available: https://www.extremetech.com/extreme/252112-what-is-a-self-driving-car.
                    [Accessed: 29-Nov-2018].</li>

            </ol>
    </body>
</html>